{
    "abstract": "We consider regularized support vector machines (SVMs) and show that\nthey are precisely equivalent to a new robust optimization\nformulation. We show that this equivalence of robust optimization\nand regularization has implications for both algorithms, and\nanalysis. In terms of algorithms, the equivalence suggests more\ngeneral SVM-like algorithms for classification that explicitly build\nin protection to noise, and at the same time control overfitting. On\nthe analysis front, the equivalence of robustness and regularization\nprovides a robust optimization interpretation for the success of\nregularized SVMs. We use this new robustness interpretation of SVMs\nto give a new proof of consistency of (kernelized) SVMs, thus\nestablishing robustness as the <i>reason</i> regularized SVMs\ngeneralize well.",
    "authors": [
        "Huan Xu",
        "Constantine Caramanis",
        "Shie Mannor"
    ],
    "id": "xu09b",
    "issue": 51,
    "pages": [
        1485,
        1510
    ],
    "title": "Robustness and Regularization of Support Vector Machines",
    "volume": "10",
    "year": "2009"
}