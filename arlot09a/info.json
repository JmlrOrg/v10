{
    "abstract": "<p>\nPenalization procedures often suffer from their dependence on\nmultiplying factors, whose optimal values are either unknown or hard\nto estimate from data. We propose a completely data-driven calibration\nalgorithm for these parameters in the least-squares regression\nframework, without assuming a particular shape for the penalty.  Our\nalgorithm relies on the concept of minimal penalty, recently\nintroduced by Birg&#233; and Massart (2007) in the context of penalized\nleast squares for Gaussian homoscedastic regression.  On the positive\nside, the minimal penalty can be evaluated from the data themselves,\nleading to a data-driven estimation of an optimal penalty which can be\nused in practice; on the negative side, their approach heavily relies\non the homoscedastic Gaussian nature of their stochastic framework.\n</p>\n<p>\nThe purpose of this paper is twofold: stating a more general\nheuristics for designing a data-driven penalty (the <i>slope\nheuristics</i>) and proving that it works for penalized least-squares\nregression with a random design, even for heteroscedastic non-Gaussian\ndata.  For technical reasons, some exact mathematical results will be\nproved only for regressogram bin-width selection. This is at least a\nfirst step towards further results, since the approach and the method\nthat we use are indeed general.\n</p>",
    "authors": [
        "Sylvain Arlot",
        "Pascal Massart"
    ],
    "id": "arlot09a",
    "issue": 9,
    "pages": [
        245,
        279
    ],
    "title": "Data-driven Calibration of Penalties for Least-Squares Regression",
    "volume": "10",
    "year": "2009"
}